#!/usr/bin/env python3
"""
라즈베리파이 카메라를 사용한 실시간 얼굴 나이 추정 프로젝트
OpenCV DNN 모듈을 사용하여 얼굴 감지 및 나이 추정을 수행합니다.
(최적화 버전 - 멀티스레딩 및 프레임 스킵 적용)
"""

import cv2
import numpy as np
import os
import sys
import time
from threading import Thread, Lock
from collections import deque

# 모델 파일 경로
MODEL_DIR = "models"
FACE_PROTO = os.path.join(MODEL_DIR, "deploy.prototxt")
FACE_MODEL = os.path.join(MODEL_DIR, "res10_300x300_ssd_iter_140000.caffemodel")
AGE_PROTO = os.path.join(MODEL_DIR, "age_deploy.prototxt")
AGE_MODEL = os.path.join(MODEL_DIR, "age_net.caffemodel")

# 나이 그룹 레이블
AGE_BUCKETS = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', 
               '(25-32)', '(38-43)', '(48-53)', '(60-100)']

# 나이 그룹 중간값 - 더 세밀하게 조정
AGE_MIDPOINTS = [1, 5, 10, 17, 28, 40, 50, 80]

# 최적화된 모델 입력 크기
FACE_INPUT_SIZE = (300, 300)
AGE_INPUT_SIZE = (227, 227)

# 평균값 (BGR) - 원본 모델 학습 시 사용된 값
MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)

# 얼굴 감지 신뢰도 임계값
CONFIDENCE_THRESHOLD = 0.7

# 최적화 설정
PROCESS_EVERY_N_FRAMES = 3  # N 프레임마다 처리 (3으로 증가)
FRAME_WIDTH = 320  # 해상도 더 축소
FRAME_HEIGHT = 240



class CameraThread:
    """비동기 카메라 캡처 스레드"""
    
    def __init__(self, camera, camera_type):
        self.camera = camera
        self.camera_type = camera_type
        self.frame = None
        self.stopped = False
        self.lock = Lock()
        
    def start(self):
        Thread(target=self._update, daemon=True).start()
        return self
    
    def _update(self):
        while not self.stopped:
            if self.camera_type == "picamera2":
                frame = self.camera.capture_array()
                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                ret = True
            else:
                ret, frame = self.camera.read()
            
            if ret:
                with self.lock:
                    self.frame = frame
    
    def read(self):
        with self.lock:
            return self.frame.copy() if self.frame is not None else None
    
    def stop(self):
        self.stopped = True


class AgeEstimator:
    """얼굴 나이 추정 클래스 (최적화 버전)"""
    
    def __init__(self):
        """모델 초기화"""
        print("모델 로딩 중...")
        
        self._check_model_files()
        
        # 얼굴 감지 모델 로드
        self.face_net = cv2.dnn.readNet(FACE_MODEL, FACE_PROTO)
        print("얼굴 감지 모델 로드 완료")
        
        # 나이 추정 모델 로드
        self.age_net = cv2.dnn.readNet(AGE_MODEL, AGE_PROTO)
        print("나이 추정 모델 로드 완료")
        
        # 라즈베리파이에서는 CPU 사용
        self.face_net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
        self.face_net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
        self.age_net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
        self.age_net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
        
        # 이전 결과 캐싱 (프레임 스킵 시 사용)
        self.cached_results = []
        
        print("모델 초기화 완료!")
    
    def _check_model_files(self):
        """모델 파일 존재 확인"""
        required_files = [FACE_PROTO, FACE_MODEL, AGE_PROTO, AGE_MODEL]
        missing_files = [f for f in required_files if not os.path.exists(f)]
        
        if missing_files:
            print("다음 모델 파일이 없습니다:")
            for f in missing_files:
                print(f"  - {f}")
            print("\n먼저 download_models.py를 실행하세요:")
            print("  python3 download_models.py")
            sys.exit(1)
    
    def detect_faces(self, frame):
        """프레임에서 얼굴 감지 (최적화)"""
        h, w = frame.shape[:2]
        
        # 작은 크기로 리사이즈하여 처리 속도 향상
        blob = cv2.dnn.blobFromImage(
            frame, 1.0, FACE_INPUT_SIZE, 
            (104.0, 177.0, 123.0), 
            swapRB=False, crop=False
        )
        
        self.face_net.setInput(blob)
        detections = self.face_net.forward()
        
        faces = []
        for i in range(detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            
            if confidence > CONFIDENCE_THRESHOLD:
                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                x1, y1, x2, y2 = box.astype("int")
                
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(w, x2)
                y2 = min(h, y2)
                
                if x2 > x1 and y2 > y1:
                    faces.append({
                        'box': (x1, y1, x2, y2),
                        'confidence': float(confidence)
                    })
        
        return faces
    
    def estimate_age(self, frame, face_box):
        """얼굴 영역에서 나이 추정 (개선된 버전)"""
        x1, y1, x2, y2 = face_box
        h, w = frame.shape[:2]
        
        # 얼굴 영역만 정확히 추출 (마진 최소화)
        # 이 모델은 얼굴만 있을 때 더 정확함
        face_w = x2 - x1
        face_h = y2 - y1
        
        # 약간의 마진만 추가 (10%)
        margin = 0.1
        margin_x = int(face_w * margin)
        margin_y = int(face_h * margin)
        
        x1_ext = max(0, x1 - margin_x)
        y1_ext = max(0, y1 - margin_y)
        x2_ext = min(w, x2 + margin_x)
        y2_ext = min(h, y2 + margin_y)
        
        face_img = frame[y1_ext:y2_ext, x1_ext:x2_ext]
        
        if face_img.size == 0 or face_img.shape[0] < 20 or face_img.shape[1] < 20:
            return None, 0.0, None, None
        
        # 원본 이미지 그대로 사용 (정규화 제거 - 모델이 원본에 맞춰 학습됨)
        blob = cv2.dnn.blobFromImage(
            face_img, 1.0, AGE_INPUT_SIZE,
            MODEL_MEAN_VALUES, swapRB=False
        )
        
        self.age_net.setInput(blob)
        age_preds = self.age_net.forward()[0]
        
        # 소프트맥스 확률 분포 확인
        age_idx = age_preds.argmax()
        confidence = float(age_preds[age_idx])
        
        # 전체 확률 분포를 사용한 기대값 계산
        # 이 방식이 단순 argmax보다 더 정확함
        expected_age = sum(p * m for p, m in zip(age_preds, AGE_MIDPOINTS))
        
        age = AGE_BUCKETS[age_idx]
        
        # 디버깅용 확률 분포
        probs = {AGE_BUCKETS[i]: f"{age_preds[i]*100:.1f}%" for i in range(len(AGE_BUCKETS))}
        
        return age, confidence, expected_age, probs
    
    def process_frame(self, frame, use_cache=False):
        """프레임 처리 및 결과 시각화"""
        if use_cache and self.cached_results:
            results = self.cached_results
        else:
            faces = self.detect_faces(frame)
            
            results = []
            for face in faces:
                result = self.estimate_age(frame, face['box'])
                
                if result[0]:  # age가 None이 아닌 경우
                    age, age_conf, expected_age, probs = result
                    results.append({
                        'box': face['box'],
                        'face_confidence': face['confidence'],
                        'age': age,
                        'age_confidence': age_conf,
                        'expected_age': expected_age,
                        'probs': probs
                    })
            
            self.cached_results = results
        
        # 결과 시각화
        for r in results:
            x1, y1, x2, y2 = r['box']
            
            # 얼굴 경계 상자
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # 나이 표시 (기대값 사용)
            expected = r.get('expected_age', 0)
            label = f"Age: ~{int(expected)}"
            
            # 상위 예측 범위도 표시
            label2 = f"{r['age']} ({int(r['age_confidence']*100)}%)"
            
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            label2_size, _ = cv2.getTextSize(label2, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)
            
            # 배경 박스
            box_height = label_size[1] + label2_size[1] + 20
            cv2.rectangle(frame, 
                         (x1, y1 - box_height),
                         (x1 + max(label_size[0], label2_size[0]) + 10, y1),
                         (0, 255, 0), -1)
            
            # 텍스트
            cv2.putText(frame, label,
                       (x1 + 5, y1 - label2_size[1] - 12),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                       (0, 0, 0), 2)
            
            cv2.putText(frame, label2,
                       (x1 + 5, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4,
                       (0, 0, 0), 1)
            
            # 콘솔에 상세 확률 출력 (디버깅)
            if not use_cache and r.get('probs'):
                print(f"나이 확률 분포: {r['probs']}")
        
        return frame, results


def init_camera():
    """카메라 초기화 (최적화된 설정)"""
    camera = None
    
    # 방법 1: picamera2 사용
    try:
        from picamera2 import Picamera2
        print("Picamera2를 사용하여 라즈베리파이 카메라 초기화...")
        camera = Picamera2()
        
        # 사용 가능한 카메라 확인
        camera_info = camera.global_camera_info()
        if len(camera_info) == 0:
            raise Exception("연결된 카메라가 없습니다")
        
        config = camera.create_preview_configuration(
            main={"format": "RGB888", "size": (FRAME_WIDTH, FRAME_HEIGHT)}
        )
        camera.configure(config)
        camera.start()
        time.sleep(2)
        print("라즈베리파이 카메라 초기화 완료!")
        return camera, "picamera2"
    except ImportError:
        print("Picamera2를 사용할 수 없습니다. OpenCV VideoCapture를 시도합니다...")
    except Exception as e:
        print(f"Picamera2 초기화 실패: {e}")
        if camera:
            try:
                camera.close()
            except:
                pass
    
    # 방법 2: OpenCV VideoCapture 사용 (V4L2 직접 사용)
    print("OpenCV VideoCapture를 사용하여 카메라 초기화...")
    
    # GStreamer 대신 V4L2 백엔드 직접 사용
    camera = cv2.VideoCapture(0, cv2.CAP_V4L2)
    
    if not camera.isOpened():
        camera = cv2.VideoCapture('/dev/video0', cv2.CAP_V4L2)
    
    if camera.isOpened():
        # MJPG 포맷 사용 (더 빠름)
        camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
        camera.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
        camera.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)
        camera.set(cv2.CAP_PROP_FPS, 30)
        camera.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        print("USB/일반 카메라 초기화 완료!")
        return camera, "opencv"
    
    print("카메라를 찾을 수 없습니다!")
    return None, None


def release_camera(camera, camera_type):
    """카메라 자원 해제"""
    if camera_type == "picamera2":
        camera.stop()
    else:
        camera.release()


def main():
    """메인 함수"""
    print("=" * 50)
    print("실시간 얼굴 나이 추정 시스템 (최적화 버전)")
    print("라즈베리파이 + OpenCV")
    print("=" * 50)
    print()
    
    # 나이 추정기 초기화
    estimator = AgeEstimator()
    
    # 카메라 초기화
    camera, camera_type = init_camera()
    if camera is None:
        print("카메라 초기화 실패!")
        sys.exit(1)
    
    # 비동기 카메라 스레드 시작
    cam_thread = CameraThread(camera, camera_type).start()
    time.sleep(1)  # 스레드 안정화 대기
    
    print()
    print("시스템 시작됨!")
    print(f"해상도: {FRAME_WIDTH}x{FRAME_HEIGHT}")
    print(f"처리 주기: {PROCESS_EVERY_N_FRAMES}프레임마다")
    print("'q' 키를 누르면 종료됩니다.")
    print("'s' 키를 누르면 현재 프레임을 저장합니다.")
    print()
    
    # FPS 계산용 변수
    fps_counter = deque(maxlen=30)
    frame_count = 0
    
    # 저장 디렉토리 생성
    save_dir = "captured"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    try:
        while True:
            start_time = time.time()
            
            # 비동기로 프레임 읽기
            frame = cam_thread.read()
            
            if frame is None:
                continue
            
            frame_count += 1
            
            # N 프레임마다 처리, 나머지는 캐시 사용
            use_cache = (frame_count % PROCESS_EVERY_N_FRAMES != 0)
            processed_frame, results = estimator.process_frame(frame, use_cache)
            
            # FPS 계산
            fps_counter.append(time.time() - start_time)
            if len(fps_counter) > 0:
                avg_time = sum(fps_counter) / len(fps_counter)
                fps = 1.0 / avg_time if avg_time > 0 else 0
            else:
                fps = 0
            
            # FPS 표시
            cv2.putText(processed_frame, f"FPS: {fps:.1f}",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                       (0, 255, 255), 2)
            
            # 감지된 얼굴 수 표시
            cv2.putText(processed_frame, f"Faces: {len(results)}",
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                       (0, 255, 255), 2)
            
            # 결과 화면 표시
            cv2.imshow("Age Estimation", processed_frame)
            
            # 키 입력 처리
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                print("종료합니다...")
                break
            elif key == ord('s'):
                timestamp = int(time.time())
                filename = os.path.join(save_dir, f"capture_{timestamp}.jpg")
                cv2.imwrite(filename, processed_frame)
                print(f"이미지 저장됨: {filename}")
    
    except KeyboardInterrupt:
        print("\n키보드 인터럽트 감지. 종료합니다...")
    
    finally:
        cam_thread.stop()
        release_camera(camera, camera_type)
        cv2.destroyAllWindows()
        print("프로그램 종료.")


if __name__ == "__main__":
    main()